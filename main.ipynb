{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabianaAndrade/projeto_IA/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Aryane de Alcantara Chaves - 11893303\n",
        "*   Fabiana Andrade Barroso - 13729431\n",
        "*   Gabriel Kennuy de Assis Malta Peruso - 13673173\n",
        "*   Ingrid Moreno da Silva - 13729070\n",
        "*   Izabel Christine dos Santos Barranco  - 11847711\n",
        "*   Jenifer Galvão de Morais - 11912147\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SnQQgn4SQM3Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkCUU_VNvjsb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Ler os dados dos arquivos\n",
        "X_file = 'X.txt'\n",
        "Y_file = 'Y_letra.txt' # pular linha no final do arquivo quando for subir\n",
        "\n",
        "with open(X_file, 'r') as file:\n",
        "    linhas_X = file.readlines()\n",
        "\n",
        "with open(Y_file, 'r') as file:\n",
        "    rotulos = file.readlines()\n",
        "\n",
        "# 2. Codificação dos rótulos (Y_letra.txt)\n",
        "classes = sorted(set(rotulos))  # Obter todas as classes únicas\n",
        "num_classes = len(classes) # Usar este valor para o parametro de quantidade de neuronios de saida\n",
        "\n",
        "rotulos_encoded = []\n",
        "for rotulo in rotulos:\n",
        "    index = classes.index(rotulo)  # Obter o índice da classe no vetor de classes\n",
        "    one_hot = [0] * num_classes\n",
        "    one_hot[index] = 1  # Definir o valor 1 para a classe correspondente\n",
        "    rotulos_encoded.append(one_hot)\n",
        "\n",
        "x = []\n",
        "for linha in linhas_X:\n",
        "    valores = linha.strip().split(',')\n",
        "    valores_int = [int(valor) for valor in valores if valor.strip()]  # Remover valores vazios e espaços em branco\n",
        "    if valores_int:\n",
        "        x.append(valores_int)\n",
        "\n",
        "\n",
        "x = np.array(x, dtype=int)  # Convertendo para int\n",
        "y = np.array(rotulos_encoded)\n",
        "tamanho_vetor = len(x[0]) # Usar esse valor para o parametro de quantidade de neuronios de entrada\n",
        "\n",
        "print(\"x \", x[0])\n",
        "print(\"y \", y[26])"
      ],
      "metadata": {
        "id": "9F7-RZyx2vl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "    # quantidade de neuronios de entrada = quantidade de valores do vetor/matriz do input\n",
        "    # quantidade de neuronios da camada escondida = pode ser um parametro\n",
        "    # quantidade de neuronios da camada de saida = quantidade de labels existentes do problema extraidas do arquivo y_letra\n",
        "    def __init__(self, input_layer_size, hidden_layer_size, output_layer_size):\n",
        "        self.input_layer_size = input_layer_size\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "        self.output_layer_size = output_layer_size\n",
        "\n",
        "        # Inicialização aleatória dos pesos e bias a partir de uma distribuição normal (gaussiana) com média 0 e desvio padrão 1.\n",
        "        self.weights_input_hidden_layer = np.random.randn(self.input_layer_size, self.hidden_layer_size)\n",
        "        self.weights_hidden_output_layer = np.random.randn(self.hidden_layer_size, self.output_layer_size)\n",
        "\n",
        "        # Inicialização dos bias\n",
        "        self.bias_hidden_layer = np.random.randn(1, self.hidden_layer_size)\n",
        "        self.bias_output_layer = np.random.randn(1, self.output_layer_size)\n",
        "\n",
        "    def foward(self, initial_input):\n",
        "        # Calculo do input da camada escondida\n",
        "        # Calcula atraves da multiplicação do valores da camada de entrada com o pesos da camada de entrada para a camada escondida\n",
        "        # e soma com os bias da camada de entrada para a camada escondida\n",
        "        self.hidden_layer_input = np.dot(initial_input, self.weights_input_hidden_layer) + self.bias_hidden_layer\n",
        "        # Calculo do output da camada escondida\n",
        "        # Calcula atraves do resultado do input da camada escondida passando pela função sigmoide\n",
        "        self.hidden_layer_output = self.sigmoid(self.hidden_layer_input)\n",
        "\n",
        "        # Calculo valores camada de saida, mesmo comportamento da camada escondida\n",
        "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output_layer) + self.bias_output_layer\n",
        "        self.output_layer_output = self.sigmoid(self.output_layer_input)\n",
        "\n",
        "        return self.output_layer_output\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n"
      ],
      "metadata": {
        "id": "0Fv7pMDsWD2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define o diretório de output\n",
        "\n",
        "output_dir = \"output_files\"\n",
        "# Cria diretório de output\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "vLsORWIyDZuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função criada para salvar os pesos iniciais no .txt\n",
        "\n",
        "def save_initial_weights(initial_weights):\n",
        "    # Define o caminho e o nome do arquivo de saída\n",
        "    output_file = \"initial_weights.txt\"\n",
        "\n",
        "    # Abre o arquivo para escrita\n",
        "    with open(output_file, \"w\") as txt_file:\n",
        "        # Escreve um cabeçalho indicando a origem dos pesos\n",
        "        txt_file.write(\"Pesos Iniciais:\\n\\n\")\n",
        "\n",
        "        # Itera sobre cada camada de pesos\n",
        "        for index, layer in enumerate(initial_weights):\n",
        "            # Determina a origem da camada de pesos\n",
        "            if index == 0:\n",
        "                txt_file.write(\"Passagem da camada sensorial para a camada escondida\\n\\n\")\n",
        "            elif index == 1:\n",
        "                txt_file.write(\"Passagem da camada escondida para a camada de saída\\n\\n\")\n",
        "\n",
        "            # Itera sobre os neurônios na camada\n",
        "            for neuron_index, weights in enumerate(layer):\n",
        "                # Escreve os pesos do neurônio\n",
        "                txt_file.write(\"Neurônio: \" + str(neuron_index + 1) + \":\\n\")\n",
        "                for weight in weights:\n",
        "                    txt_file.write(str(weight) + \" \")\n",
        "                txt_file.write(\"\\n\")\n",
        "\n",
        "            # Adiciona uma linha em branco entre as camadas\n",
        "            txt_file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "fG9ydwzjGekP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função criada para salvar os pesos finais no .txt\n",
        "\n",
        "def save_final_weights(final_weights):\n",
        "    # Define o caminho e o nome do arquivo de saída\n",
        "    output_file = \"final_weights.txt\"\n",
        "\n",
        "    # Abre o arquivo para escrita\n",
        "    with open(output_file, \"w\") as txt_file:\n",
        "        # Escreve um cabeçalho indicando a origem dos pesos\n",
        "        txt_file.write(\"Pesos Finais:\\n\\n\")\n",
        "\n",
        "        # Itera sobre cada camada de pesos\n",
        "        for index, layer in enumerate(final_weights):\n",
        "            # Determina a origem da camada de pesos\n",
        "            if index == 0:\n",
        "                txt_file.write(\"Passagem da camada sensorial para a camada escondida\\n\\n\")\n",
        "            elif index == 1:\n",
        "                txt_file.write(\"Passagem da camada escondida para a camada de saída\\n\\n\")\n",
        "\n",
        "            # Itera sobre os neurônios na camada\n",
        "            for neuron_index, weights in enumerate(layer):\n",
        "                # Escreve os pesos do neurônio\n",
        "                txt_file.write(\"Neurônio: \" + str(neuron_index + 1) + \":\\n\")\n",
        "                for weight in weights:\n",
        "                    txt_file.write(str(weight) + \" \")\n",
        "                txt_file.write(\"\\n\")\n",
        "\n",
        "            # Adiciona uma linha em branco entre as camadas\n",
        "            txt_file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "wI-PCYR3MSwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função criada para salvar os parametros no .txt\n",
        "\n",
        "def save_architecture_parameters(learning_rate, stopping_criteria, input_neurons, hidden_neurons, output_neurons):\n",
        "    # Define o caminho e o nome do arquivo de saída\n",
        "    output_file = \"architecture_parameters.txt\"\n",
        "\n",
        "    # Abre o arquivo para escrita\n",
        "    with open(output_file, \"w\") as txt_ParametersFile:\n",
        "        txt_ParametersFile.write(\"Taxa de aprendizado: \" +\n",
        "                        str(learning_rate) + \"\\n\")\n",
        "        txt_ParametersFile.write(\"Critério de parada: \" +\n",
        "                        str(stopping_criteria) + \"\\n\")\n",
        "        txt_ParametersFile.write(\"Nro de neurônios (camada de entrada): \" +\n",
        "                        str(input_neurons) + \"\\n\")\n",
        "        txt_ParametersFile.write(\"Nro de neurônios (camada oculta): \" +\n",
        "                        str(hidden_neurons) + \"\\n\")\n",
        "        txt_ParametersFile.write(\"Nro de neurônios (camada de saída): \" +\n",
        "                        str(output_neurons) + \"\\n\")\n",
        "    txt_ParametersFile.close()\n",
        "    # Fecha o arquivo"
      ],
      "metadata": {
        "id": "_39XD95BHCa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função criada para salvar os erros por epoca no .txt\n",
        "\n",
        "def save_error_by_epoch(error, epoch):\n",
        "    # Define o caminho e o nome do arquivo de saída\n",
        "    output_file = \"error_by_epoch.txt\"\n",
        "\n",
        "    # Abre o arquivo para escrita\n",
        "    with open(output_file, \"a\") as txt_file:\n",
        "        # Escreve a média de erro da época\n",
        "        txt_file.write(\"Média de erro da época \" + str(epoch) + \": \" +\n",
        "                        str(error) + \"\\n\")\n",
        "\n",
        "    # Não é preciso fechar pois estamos usando appende ao inves de write"
      ],
      "metadata": {
        "id": "65HHFb5DOdoU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}